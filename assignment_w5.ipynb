{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Text classification with Naive Bayes  \n",
    "        \n",
    "        \n",
    "        \n",
    "<h3>Abstract</h3>\n",
    "<p>We will do text classification on a collection of Dutch parliamentary questions.\n",
    "    The website <a href=\"https://zoek.officielebekendmakingen.nl/zoeken/parlementaire_documenten\">officielebekendmakingen.nl</a>lets you search in \"kamervragen\".\n",
    "    <!--You can donwload\n",
    "    <a href='http://data.politicalmashup.nl/kamervragen/PoliDocs_Kamervragen.zip'>this zipfile with Kamervragen in XML</a>\n",
    "    to see some of the  data in XML format. \n",
    "    It also contains style sheets to show the XML well in a browser.  \n",
    "-->\n",
    "    The <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/'>MYSQL directory</a> contains an <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR14807.xml'>example   Kamervraag XML file</a> and a file `kvr.csv.gz` with 40K kamervragen in a handy csv format. Note that in your browser you see the result of applying stylesheets. So choose View Source or open it in an editor.</p>\n",
    "\n",
    "<h3>First exploration</h3>\n",
    "\n",
    "See below.\n",
    "\n",
    "<h2>Exercises</h2>\n",
    "\n",
    "<p>We will use the fields in elements of the form <tt> &lt;item attribuut=\"Afkomstig_van\"></tt> as our classes. \n",
    "    These are the ministeries to whom the question is addressed.\n",
    "    An example is \n",
    "    <pre>\n",
    "        &lt;item attribuut=\"Afkomstig_van\">Landbouw, Natuurbeheer en Visserij (LNV)&lt;/item>\n",
    "    </pre>\n",
    "    Note that these labels are <strong>not normalized</strong>, see e.g. the counts below:\n",
    "    <pre>\n",
    "Justitie (JUS)                                                   3219\n",
    "Volksgezondheid, Welzijn en Sport (VWS)                          2630\n",
    "Buitenlandse Zaken (BUZA)                                        1796\n",
    "Verkeer en Waterstaat (VW)                                       1441\n",
    "Justitie                                                         1333\n",
    "Sociale Zaken en Werkgelegenheid (SZW)                           1231\n",
    "Onderwijs, Cultuur en Wetenschappen (OCW)                        1187\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer (VROM)     984\n",
    "FinanciÃ«n (FIN)                                                   960\n",
    "Volksgezondheid, Welzijn en Sport                                 951\n",
    "Economische Zaken (EZ)                                            946\n",
    "Buitenlandse Zaken                                                753\n",
    "Binnenlandse Zaken en Koninkrijksrelaties (BZK)                   725\n",
    "Verkeer en Waterstaat                                             724\n",
    "Defensie (DEF)                                                    646\n",
    "Sociale Zaken en Werkgelegenheid                                  607\n",
    "Landbouw, Natuurbeheer en Visserij (LNV)                          586\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer            554\n",
    "Onderwijs, Cultuur en Wetenschappen                               532\n",
    "Vreemdelingenzaken en Integratie (VI)                             466\n",
    "    </pre>\n",
    "</p>\n",
    "\n",
    "\n",
    "<h2>Form of handing in your final product</h2>\n",
    "\n",
    "* An IPython notebook with for each question, a MarkDown cell containing the question, a code cell which solves the question, an output cell with the output, followed by a MarkDown cell with explanation/reflection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8103, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaar</th>\n",
       "      <th>partij</th>\n",
       "      <th>titel</th>\n",
       "      <th>vraag</th>\n",
       "      <th>antwoord</th>\n",
       "      <th>ministerie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000115403.xml</th>\n",
       "      <td>1986</td>\n",
       "      <td></td>\n",
       "      <td>Welke zijn de gevolgen van de beslissing om d...</td>\n",
       "      <td>De overeenkomsten van 14 oktober 1985 bevatte...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V040508590.xml</th>\n",
       "      <td>2005</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Vragen naar aanleiding van een ANP-bericht va...</td>\n",
       "      <td>Deelt u de opvatting dat «de uiterste inspann...</td>\n",
       "      <td>ANP-bericht, 11 februari 2005 Kamerstuk 27 92...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR8178.xml</th>\n",
       "      <td>1998</td>\n",
       "      <td>CDA</td>\n",
       "      <td></td>\n",
       "      <td>Hoe verklaart u de toename van het aantal all...</td>\n",
       "      <td>In de eerste acht maanden van 1997 meldden zi...</td>\n",
       "      <td>Justitie (JUS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000019654.xml</th>\n",
       "      <td>1991</td>\n",
       "      <td>Groen Links</td>\n",
       "      <td></td>\n",
       "      <td>Hebt u kennis genomen van de inhoud en conclu...</td>\n",
       "      <td>Ja. In het kader van het CFK-aktieprogramma l...</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR9578.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>D66</td>\n",
       "      <td>Vragen naar aanleiding van de uitspraak van d...</td>\n",
       "      <td>Bent u op de hoogte van de uitspraak van de a...</td>\n",
       "      <td>Ja. Nadat de kinderen door de moeder in Neder...</td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  jaar        partij  \\\n",
       " 0000115403.xml   1986                 \n",
       " V040508590.xml   2005           CDA   \n",
       " KVR8178.xml      1998           CDA   \n",
       " 0000019654.xml   1991   Groen Links   \n",
       " KVR9578.xml      1999           D66   \n",
       "\n",
       "                                                             titel  \\\n",
       " 0000115403.xml   Welke zijn de gevolgen van de beslissing om d...   \n",
       " V040508590.xml   Vragen naar aanleiding van een ANP-bericht va...   \n",
       " KVR8178.xml                                                         \n",
       " 0000019654.xml                                                      \n",
       " KVR9578.xml      Vragen naar aanleiding van de uitspraak van d...   \n",
       "\n",
       "                                                             vraag  \\\n",
       " 0000115403.xml   De overeenkomsten van 14 oktober 1985 bevatte...   \n",
       " V040508590.xml   Deelt u de opvatting dat «de uiterste inspann...   \n",
       " KVR8178.xml      Hoe verklaart u de toename van het aantal all...   \n",
       " 0000019654.xml   Hebt u kennis genomen van de inhoud en conclu...   \n",
       " KVR9578.xml      Bent u op de hoogte van de uitspraak van de a...   \n",
       "\n",
       "                                                          antwoord  \\\n",
       " 0000115403.xml                                                nan   \n",
       " V040508590.xml   ANP-bericht, 11 februari 2005 Kamerstuk 27 92...   \n",
       " KVR8178.xml      In de eerste acht maanden van 1997 meldden zi...   \n",
       " 0000019654.xml   Ja. In het kader van het CFK-aktieprogramma l...   \n",
       " KVR9578.xml      Ja. Nadat de kinderen door de moeder in Neder...   \n",
       "\n",
       "                      ministerie  \n",
       " 0000115403.xml              nan  \n",
       " V040508590.xml              nan  \n",
       " KVR8178.xml      Justitie (JUS)  \n",
       " 0000019654.xml              nan  \n",
       " KVR9578.xml            Justitie  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names=['jaar', 'partij','titel','vraag','antwoord','ministerie']\n",
    "\n",
    "# Change to KVR1000.csv.gz if this becomes too slow for you\n",
    "# kvrdf= pd.read_csv('http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR.csv.gz', \n",
    "kvrdf= pd.read_csv('http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR.csv.gz', \n",
    "                   compression='gzip', sep='\\t', \n",
    "                   index_col=0, names=names,\n",
    "                   ) \n",
    "\n",
    "for kolom in names[1:]:\n",
    "    kvrdf[kolom]= kvrdf[kolom].astype(str)\n",
    "\n",
    "train = kvrdf.sample(frac=0.2,random_state=200)\n",
    "test = kvrdf.drop(train.index)\n",
    "\n",
    "kvrdf = train\n",
    "\n",
    "print(kvrdf.shape)\n",
    "kvrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from math import log\n",
    "\n",
    "DutchStop= stopwords.words('dutch')\n",
    "allvragen= '\\n'.join(list(kvrdf.vraag))\n",
    "classes = list(set(list(kvrdf.ministerie)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are treated as lowercase & stopwords are filtered out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequencies per word\n",
    "\n",
    "def strip_string(string):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param string: string of unfiltered word/symbols\n",
    "    :return: list of all tokens extracted from the string (lowercasing, stopwords, alpha)\n",
    "    \"\"\"\n",
    "    return [w for w in nltk.word_tokenize(string.lower()) if w.isalpha() and not w in set(DutchStop)]\n",
    "\n",
    "def str_to_tf(string):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param string: string of unfiltered word/symbols\n",
    "    :return: dictionary of all term frequencies: occurance of term in string\n",
    "    \"\"\"\n",
    "    return Counter(strip_string(string))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str_to_tk(string):\n",
    "    \"\"\" returns token count in a string\n",
    "    \"\"\"\n",
    "    return len(strip_string(string))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "Normalize the values for \"ministerie\" and choose 10 ministeries to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Justitie', 'Financien', 'Verkeer en Waterstaat', 'Buitenlandse Zaken', 'Onderwijs, Cultuur en Wetenschappen', 'Sociale Zaken en Werkgelegenheid', 'Economische Zaken', 'Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer', 'Volksgezondheid, Welzijn en Sport', 'Landbouw, Natuurbeheer en Visserij'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\uva\\zoekmachines\\zmsenv\\lib\\site-packages\\pandas\\core\\generic.py:4388: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  object.__getattribute__(self, name)\n",
      "d:\\uva\\zoekmachines\\zmsenv\\lib\\site-packages\\pandas\\core\\generic.py:4389: FutureWarning: Attribute 'is_copy' is deprecated and will be removed in a future version.\n",
      "  return object.__setattr__(self, name, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaar</th>\n",
       "      <th>partij</th>\n",
       "      <th>titel</th>\n",
       "      <th>vraag</th>\n",
       "      <th>antwoord</th>\n",
       "      <th>ministerie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KVR8178.xml</th>\n",
       "      <td>1998</td>\n",
       "      <td>CDA</td>\n",
       "      <td></td>\n",
       "      <td>Hoe verklaart u de toename van het aantal all...</td>\n",
       "      <td>In de eerste acht maanden van 1997 meldden zi...</td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR9578.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>D66</td>\n",
       "      <td>Vragen naar aanleiding van de uitspraak van d...</td>\n",
       "      <td>Bent u op de hoogte van de uitspraak van de a...</td>\n",
       "      <td>Ja. Nadat de kinderen door de moeder in Neder...</td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR16328.xml</th>\n",
       "      <td>2002</td>\n",
       "      <td>GroenLinks</td>\n",
       "      <td>Vragen naar aanleiding van een bericht over e...</td>\n",
       "      <td>Kent u het bericht over een toename van meldi...</td>\n",
       "      <td>Ja. De toename van het aantal meldingen over ...</td>\n",
       "      <td>Onderwijs, Cultuur en Wetenschappen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR6500.xml</th>\n",
       "      <td>1997</td>\n",
       "      <td>GroenLinks</td>\n",
       "      <td>Vragen over besmetting van vlees als gevolg v...</td>\n",
       "      <td>Kent u het bericht dat volgens de microbioloo...</td>\n",
       "      <td>Ja. Het bericht is gebaseerd op het onderzoek...</td>\n",
       "      <td>Landbouw, Natuurbeheer en Visserij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR5330.xml</th>\n",
       "      <td>1997</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Vragen over het nader onderzoek naar de voorm...</td>\n",
       "      <td>Wanneer wordt in de relevante politierapporte...</td>\n",
       "      <td>Het nadere onderzoek dat ik uw Kamer bij mijn...</td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                jaar       partij  \\\n",
       " KVR8178.xml    1998          CDA   \n",
       " KVR9578.xml    1999          D66   \n",
       " KVR16328.xml   2002   GroenLinks   \n",
       " KVR6500.xml    1997   GroenLinks   \n",
       " KVR5330.xml    1997          CDA   \n",
       "\n",
       "                                                           titel  \\\n",
       " KVR8178.xml                                                       \n",
       " KVR9578.xml    Vragen naar aanleiding van de uitspraak van d...   \n",
       " KVR16328.xml   Vragen naar aanleiding van een bericht over e...   \n",
       " KVR6500.xml    Vragen over besmetting van vlees als gevolg v...   \n",
       " KVR5330.xml    Vragen over het nader onderzoek naar de voorm...   \n",
       "\n",
       "                                                           vraag  \\\n",
       " KVR8178.xml    Hoe verklaart u de toename van het aantal all...   \n",
       " KVR9578.xml    Bent u op de hoogte van de uitspraak van de a...   \n",
       " KVR16328.xml   Kent u het bericht over een toename van meldi...   \n",
       " KVR6500.xml    Kent u het bericht dat volgens de microbioloo...   \n",
       " KVR5330.xml    Wanneer wordt in de relevante politierapporte...   \n",
       "\n",
       "                                                        antwoord  \\\n",
       " KVR8178.xml    In de eerste acht maanden van 1997 meldden zi...   \n",
       " KVR9578.xml    Ja. Nadat de kinderen door de moeder in Neder...   \n",
       " KVR16328.xml   Ja. De toename van het aantal meldingen over ...   \n",
       " KVR6500.xml    Ja. Het bericht is gebaseerd op het onderzoek...   \n",
       " KVR5330.xml    Het nadere onderzoek dat ik uw Kamer bij mijn...   \n",
       "\n",
       "                                        ministerie  \n",
       " KVR8178.xml                              Justitie  \n",
       " KVR9578.xml                              Justitie  \n",
       " KVR16328.xml  Onderwijs, Cultuur en Wetenschappen  \n",
       " KVR6500.xml    Landbouw, Natuurbeheer en Visserij  \n",
       " KVR5330.xml                              Justitie  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only return classes that are about a single ministerie.\n",
    "def determine_classes(classes):\n",
    "    \"\"\" Remove any class that spans multiple ministeries\n",
    "    \n",
    "    :param classes: All classes that occur in kamervragen\n",
    "    :return:\n",
    "        norm_classes, a subset of classes with only the classes that span a single ministerie.\n",
    "    \"\"\"\n",
    "\n",
    "    norm_classes = set()\n",
    "    \n",
    "    for c in classes:\n",
    "        add = True\n",
    "\n",
    "        if c == 'nan':\n",
    "            continue\n",
    "\n",
    "        for nc in norm_classes:\n",
    "            if nc in c:\n",
    "                add = False\n",
    "                break\n",
    "            elif c in nc:\n",
    "                norm_classes.remove(nc)\n",
    "                break\n",
    "\n",
    "        if add:\n",
    "            norm_classes.add(c)\n",
    "            \n",
    "    return norm_classes\n",
    "\n",
    "\n",
    "# Normalize class c by replacing strange e's with a normal e\n",
    "# and removing anything between parenthesis.\n",
    "def normalize_class(c):\n",
    "    \"\"\" Normalize class c by replacing different representations of the e by a normal e\n",
    "    \n",
    "    :param c: str, a single class name\n",
    "    :return:\n",
    "        str, a single class name with 'normal' e's and no trailing whitespace.\n",
    "    \"\"\"\n",
    "\n",
    "    nc = \"\"\n",
    "    parenthesis = False\n",
    "    \n",
    "    for char in c:\n",
    "        if char == '(':\n",
    "            parenthesis = True\n",
    "            \n",
    "        elif char == 'ë':\n",
    "            char = 'e'\n",
    "        elif char == 'Ã':\n",
    "            char = 'e'\n",
    "        elif char == '«':\n",
    "            char = ''\n",
    "            \n",
    "        if not parenthesis:\n",
    "            nc += char\n",
    "            \n",
    "        if char == ')':\n",
    "            parenthesis = False\n",
    "    \n",
    "    return nc.strip()\n",
    "\n",
    "\n",
    "def choose_10_classes(class_rows, norm_classes):\n",
    "    \"\"\" Only return the 10 most occuring classes.\n",
    "    \n",
    "    :param class_rows: dict, a dictionary mapping a class name to all rows that class occurs in.\n",
    "    :param norm_classes: set, all normalized class names of classes that only span a single ministerie.\n",
    "    \n",
    "    :return:\n",
    "        set, the normalized names of the 10 most occuring classes\n",
    "    \"\"\"\n",
    "    count = Counter()\n",
    "    for key, rows in class_rows.items():\n",
    "        key = normalize_class(key)\n",
    "        \n",
    "        if key in norm_classes:\n",
    "            count[key] += len(rows)\n",
    "            \n",
    "    return set([name for name, _ in count.most_common(10)])\n",
    "\n",
    "\n",
    "def kvrdf_to_10_classes(kvrdf, norm_classes):\n",
    "    \"\"\" Return a copy of kvrdf with normalized class names and only containing rows with classes in norm_classes\n",
    "    \n",
    "    :param kvrdf: pd.DataFrame, containing all downloaded information: questions, ministerie, answers, etc.\n",
    "    :param norm_classes: set, containing all normalized class names of the 10 most occuring classes.\n",
    "    \n",
    "    :return: pd.DataFrame, kvrdf but with all rows removed that don't contain any of the ministeries in norm_classes.\n",
    "    \"\"\"   \n",
    "    all_classes = set(kvrdf.ministerie)\n",
    "    \n",
    "    for i, c in enumerate(all_classes):\n",
    "        nc = normalize_class(c)\n",
    "        \n",
    "        if not (nc in norm_classes):\n",
    "            kvrdf = kvrdf[kvrdf.ministerie != c]            \n",
    "        else:\n",
    "            kvrdf.loc[kvrdf[\"ministerie\"] == c, \"ministerie\"] = nc\n",
    "            \n",
    "    return kvrdf\n",
    "\n",
    "# classes is a set of strings of all classes that are in kvrdf\n",
    "classes = set(kvrdf.ministerie)\n",
    "\n",
    "# norm classes is a set of strings of classes that only span a single ministerie with normalized names.\n",
    "norm_classes = {normalize_class(c) for c in determine_classes(classes)}\n",
    "\n",
    "# class_rows_full is a dictionary mapping a class name to all rows that contain that class.\n",
    "class_rows_full = {c:kvrdf.loc[kvrdf.ministerie == c] for c in classes}\n",
    "\n",
    "# classes is adjusted so it now is a set that contains the normalized strings of the 10 most occuring classes.\n",
    "classes = choose_10_classes(class_rows_full, norm_classes)\n",
    "print(classes)\n",
    "\n",
    "# train and test data are adjusted so any rows that don't contain the class in 'classes' are removed.\n",
    "# also, all class names are normalized.\n",
    "kvrdf = kvrdf_to_10_classes(kvrdf, classes)\n",
    "test = kvrdf_to_10_classes(test, classes)\n",
    "kvrdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Classes are extracted from the ministerie column in the dataframe. Any classes that don't occur often or span multiple ministeries, are removed from the dataframe. All other classes have their names normalized.\n",
    "\n",
    "The normalization is done by changing all variants of the 'e' in a class to a normal 'e'. Also any class that is named 'nan' were removed. And finally, any starting or trailing whitespace were removed from the class name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "Implement the two algorithms in Fig MRS.13.2, using your earlier code for creating term and document frequencies. It might be easier to use the representation and formula given in MRS section 13.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document frequencies per term\n",
    "k = [list(set(strip_string(t))) for t in kvrdf.vraag]\n",
    "\n",
    "# KLS: dfdict here to train w/ MI\n",
    "dfdict = Counter(list(itertools.chain.from_iterable(k)))\n",
    "\n",
    "#document frequencies per class per term\n",
    "def TrainMultinomialNB(pd_df, classes, V=None):\n",
    "    \"\"\" more reference from p258 onwards of MRS\n",
    "    \n",
    "    :param classes: classes which are taken into account for training\n",
    "    :param pd_df: kamervragen dataframe\n",
    "    :return:\n",
    "        V: set, of terms which which are used for classification\n",
    "        class_priors: dictionary, prior probabilities for each class: P(c) prior[class]\n",
    "        cond_prob: dictionary, conditional probabilities for each term per class: P(t|c) cond[class][term]\n",
    "        dfdict: dictionary with document frequencies\n",
    "        classes: list, classes actually used, temporary until class input is synchronised with pandas dataframe\n",
    "    \"\"\"\n",
    "    class_frequency = Counter([c for c in pd_df.ministerie])\n",
    "    \n",
    "    \n",
    "    # P(c)\n",
    "    class_priors = {c:class_frequency[c]/sum([class_frequency[cn] for cn in classes]) for c in classes}\n",
    "\n",
    "    #vocabulary\n",
    "    if not V:\n",
    "        V = set(dfdict.keys())\n",
    "    \n",
    "    # complete rows per class\n",
    "    class_rows_full = {c:kvrdf.loc[kvrdf.ministerie == c] for c in classes}\n",
    "\n",
    "    # term frequency per class\n",
    "    class_tf = {c:str_to_tf('\\n'.join(list(class_rows_full.get(c).vraag))) for c in classes}\n",
    "    \n",
    "    # token count per class (for sum over Tct' in (t' in V), (p259, formula 13.6)\n",
    "    class_tk = {c:str_to_tk('\\n'.join(list(class_rows_full.get(c).vraag))) for c in classes}\n",
    "\n",
    "    #P(t|c)\n",
    "    cond_prob = {t:{c:(class_tf[c][t] + 1)/(class_tk[c] + 1) for c in classes} for t in V}\n",
    "    \n",
    "    \n",
    "    # KLS: ... so no dfdict returned here\n",
    "    return V, class_priors, cond_prob, classes\n",
    "\n",
    "def filter_vocab(W, V):\n",
    "    \"\"\" \n",
    "    \n",
    "    :param W: list; stripped query\n",
    "    :param V: set; of vocab used for classification (determined by one or anoter method)\n",
    "    :return: a list of words that occur in the used vocabulary\n",
    "    \"\"\"\n",
    "    return [w for w in W if w in V]\n",
    "\n",
    "def ApplyMultinomialNB(classes, priors, conditionals, d, Vocab=None):\n",
    "    \"\"\" Applies a Naive Bayes classifier on previously derived priors & conditionals on a query d\n",
    "\n",
    "    :param classes: list, optional ministeries to classify between\n",
    "    :param priors: dictionary, prior probabilities for each class: P(c) prior[class]\n",
    "    :param conditionals: dictionary, conditional probabilities for each term per class: P(t|c) cond[class][term]\n",
    "    :param d: string, query\n",
    "    :param Vocab: set, of terms which which are used for classification\n",
    "    :return: best classification for query\n",
    "    \"\"\"\n",
    "    W = strip_string(d)\n",
    "    if Vocab:\n",
    "        W = filter_vocab(W, Vocab)\n",
    "    # KLS: change here to handle single class application\n",
    "    #if isinstance(priors, float):\n",
    "    #    score = {classes:log(priors)}\n",
    "    #else:\n",
    "    score = {c:log(priors[c]) for c in classes}\n",
    "\n",
    "    for c in classes:\n",
    "        score[c] += sum([log(conditionals[t][c]) for t in W if t in conditionals])\n",
    "    best_class = sorted(score, key = lambda key: score[key])[-1]\n",
    "    return best_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "On this collection, train NB text classifiers for 10 different classes with enough and interesting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLS: commented out to train later w/ MI\n",
    "V, class_priors, cond_prob, classes = TrainMultinomialNB(kvrdf, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Compute for each term and each of your 10 classes its utility for that class using mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_class_df(pddf, classes):\n",
    "    class_dfdict = {c:{} for c in classes}\n",
    "\n",
    "    for i, c in enumerate(classes):\n",
    "        for d in kvrdf[kvrdf.ministerie == c].vraag:\n",
    "            for elem in set(strip_string(d)):\n",
    "                if class_dfdict[c].get(elem, 0):\n",
    "                    class_dfdict[c][elem] += 1\n",
    "                else:\n",
    "                    class_dfdict[c][elem] = 1\n",
    "    return class_dfdict\n",
    "\n",
    "cddf = extract_class_df(kvrdf, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI(doc_freq, class_doc_freq):\n",
    "    \"\"\" creates a mutual information dictionary for each term, class pair\n",
    "    \n",
    "    :param doc_freq: dictionary, contains documents frequencies per term, doc_freq[term]\n",
    "    :param class_doc_freq: dictionary, contains documents frequencies per term per class, cdf[class][term]\n",
    "    :return MIdict: dictionary, contains mutual information for each class/term pair, MI[class][term]\n",
    "    \"\"\"\n",
    "    N = sum(doc_freq.values())\n",
    "    MIdict = {}\n",
    "    for c in class_doc_freq.keys():\n",
    "        MIdict[c] = {}\n",
    "        for t in class_doc_freq[c].keys():\n",
    "            N11 = class_doc_freq[c][t]\n",
    "            N10 = doc_freq[t] - N11\n",
    "            N01 = sum(class_doc_freq[c].values()) - class_doc_freq[c][t]\n",
    "            N00 = N - doc_freq[t] - (sum(class_doc_freq[c].values()) - class_doc_freq[c][t])\n",
    "            N1 = N11 + N10\n",
    "            N0 = N01 + N00\n",
    "            if N11:\n",
    "                MIdict[c][t] = N11/N * log( (N*N11)/(N1*N1), 2)\n",
    "            if N01:\n",
    "                MIdict[c][t] += N01/N * log( (N*N01)/(N0*N1) , 2)\n",
    "            if N10:\n",
    "                MIdict[c][t] += N10/N * log( (N*N10)/(N1*N0) , 2)\n",
    "            if N00:\n",
    "                MIdict[c][t] += N00/N * log(  (N*N00)/(N0*N0), 2)\n",
    "    return MIdict\n",
    "\n",
    "MIdict = MI(dfdict, cddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "For each class, show the top 10 words as in Figure 13.7 in MRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_MI(MIdict, N):\n",
    "    \"\"\" \n",
    "    \n",
    "    :param MIdict: a dictionary with mutual information for each MIdict[class][term]\n",
    "    :param N: top N MI terms returned per class\n",
    "    :return: a dictionary of the top N MI predictors of each class    \n",
    "    \"\"\"\n",
    "    resdict = {}\n",
    "    for c in MIdict.keys():\n",
    "        resdict[c] = sorted(MIdict[c].items(), key = lambda key: -MIdict[c][key[0]])[:N]\n",
    "    return resdict\n",
    "\n",
    "def top_MI_to_markdown(topMI):\n",
    "    firstline = classes_table_markdown(topMI)\n",
    "    rest_of_table = values_table_markdown(topMI)\n",
    "    return firstline + rest_of_table\n",
    "\n",
    "\n",
    "def classes_table_markdown(topmidict):\n",
    "    return \"| []() | \" + \" | []() | \".join(topmidict.keys()) + \"|\\n\" + \"|\" + \" | \".join(['----- | -----' for _ in topmidict.keys()]) + \"| \\n\"\n",
    "\n",
    "def values_table_markdown(topmidict):\n",
    "    returnstring = \"\"\n",
    "    for i, elem in enumerate(topmidict[list(topmidict.keys())[0]]):\n",
    "        returnstring += \" | \" + \" | \".join([pair_to_markdown(topmidict[c][i]) for c in topmidict.keys()]) + \" | \\n\"\n",
    "    return returnstring\n",
    "            \n",
    "def pair_to_markdown(pair):\n",
    "    return pair[0] + \" | \" + str(pair[1])\n",
    "\n",
    "\n",
    "def topMI_to_vocab(topmidict):\n",
    "    vocab_l_o_l = [[elem[0] for elem in topmidict[c]] for c in topmidict.keys()]\n",
    "    return set(list(itertools.chain.from_iterable(vocab_l_o_l)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topfeatures = top_MI(MIdict, 1)\n",
    "#topfeatures10 = top_MI(MIdict, 10)\n",
    "#topfeatures100 = top_MI(MIdict, 100)\n",
    "\n",
    "dfdict2 = {t:v for t,v in dfdict.items() if v > 5}\n",
    "cddf2 = {c:{t:cddf[c][t] for t in cddf[c].keys() if t in dfdict2.keys()} for c in cddf}\n",
    "\n",
    "MIdict2 = MI(dfdict2, cddf2)\n",
    "topfeatures2_30 = top_MI(MIdict2, 30)\n",
    "\n",
    "#topvocab10 = topMI_to_vocab(topfeatures2_10)\n",
    "#topvocab100 = topMI_to_vocab(topfeatures100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| []() | Justitie | []() | Financien | []() | Verkeer en Waterstaat | []() | Buitenlandse Zaken | []() | Onderwijs, Cultuur en Wetenschappen | []() | Sociale Zaken en Werkgelegenheid | []() | Economische Zaken | []() | Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer | []() | Volksgezondheid, Welzijn en Sport | []() | Landbouw, Natuurbeheer en Visserij|\n",
       "|----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -----| \n",
       " | griffier | 2.4285798500549296 | bnb | 0.5853723320925814 | tunnels | 0.9562544027350109 | un | 1.2256791892157386 | vsnu | 0.8188053099694912 | werkvoorziening | 0.8669835918569925 | gaswet | 0.6053225478094617 | bedrijventerreinen | 0.7649050958316113 | generieke | 2.203491347348963 | veevoer | 0.499002326631561 | \n",
       " | behoorlijke | 2.4285798500549296 | omzetbelasting | 0.5853723320925814 | fiets | 0.9562544027350109 | molukken | 1.2256791892157386 | onderwijsblad | 0.8188053099694912 | uitzendkrachten | 0.8669835918569925 | tnt | 0.6052934176968702 | bestemmingsplannen | 0.7649050958316113 | geneesmiddelenwet | 2.203491347348963 | diersoorten | 0.4989722449236479 | \n",
       " | averechts | 2.4285798500549296 | imf | 0.5853430360090361 | wegennet | 0.9562544027350109 | milities | 1.2256791892157386 | onderwijsbond | 0.8188053099694912 | xv | 0.8669835918569925 | afnemers | 0.6052934176968702 | wro | 0.7649050958316113 | borstkanker | 2.203491347348963 | staatsbosbeheer | 0.4989722449236479 | \n",
       " | topambtenaar | 2.4285798500549296 | tax | 0.5853430360090361 | spoorlijn | 0.9562544027350109 | ambassadeurs | 1.2256791892157386 | havo | 0.8188053099694912 | arbeidsongeschikt | 0.8669835918569925 | windenergie | 0.6052934176968702 | verbranding | 0.7648771357546459 | bedrijvenpoli | 2.203491347348963 | faunawet | 0.4989722449236479 | \n",
       " | mensensmokkel | 2.4285798500549296 | invordering | 0.5853222306708862 | inpassing | 0.9562275800396735 | civil | 1.2256791892157386 | examens | 0.8187776944239534 | werkhervatting | 0.8669835918569925 | energiesector | 0.6052727783199998 | woningstichting | 0.7648576663531585 | toetsingscommissies | 2.203491347348963 | zeehonden | 0.4989722449236479 | \n",
       " | notarissen | 2.4285798500549296 | terugbetaald | 0.5853222306708862 | rijbewijs | 0.9562275800396735 | peace | 1.2256791892157386 | middelbare | 0.8187776944239534 | arbeidsongeschikten | 0.8669835918569925 | jaarverslagen | 0.6052727783199998 | vierkante | 0.7648576663531585 | ccmo | 2.203491347348963 | laser | 0.49895065401126204 | \n",
       " | opsporingsonderzoek | 2.4285798500549296 | belastinginkomsten | 0.5853222306708862 | maximumsnelheid | 0.9562275800396735 | rwandese | 1.2256791892157386 | gemeentefonds | 0.8187585695385503 | uitvoeringsinstelling | 0.8669562671368469 | brandstofprijzen | 0.6052727783199998 | geel | 0.7648576663531585 | mensgebonden | 2.203491347348963 | zeldzame | 0.49895065401126204 | \n",
       " | kansspelbeleid | 2.4285798500549296 | aanmerkt | 0.5853055751325945 | landingsrechten | 0.9562275800396735 | strafhof | 1.2256536604819206 | bibliotheken | 0.8187585695385503 | wsw | 0.8669562671368469 | bonafide | 0.6052727783199998 | leegstand | 0.7648576663531585 | toedienen | 2.203491347348963 | dierenwelzijn | 0.49895065401126204 | \n",
       " | rechercheurs | 2.428558124460832 | monitor | 0.5853055751325945 | vervoerder | 0.9562275800396735 | hamas | 1.2256536604819206 | leermiddelen | 0.8187585695385503 | solliciteren | 0.8669374330646434 | abonnement | 0.6052727783199998 | woningbouw | 0.7648576663531585 | gvs | 2.203491347348963 | eten | 0.49895065401126204 | \n",
       " | tamil | 2.428558124460832 | schatkist | 0.5853055751325945 | snelwegen | 0.9562092479727526 | oekraïne | 1.2256536604819206 | verdelen | 0.8187585695385503 | verzekeringskamer | 0.8669374330646434 | installeren | 0.6052562887333139 | lawaai | 0.7648576663531585 | dbc | 2.203491347348963 | natuurwaarden | 0.49895065401126204 | \n",
       " | terroristen | 2.428558124460832 | ingedeeld | 0.5853055751325945 | verkeerstekens | 0.9562092479727526 | uganda | 1.2256536604819206 | erfgoed | 0.8187585695385503 | flexibele | 0.8669374330646434 | kinderarbeid | 0.6052562887333139 | planbureau | 0.7648423466816193 | verpleeghuiszorg | 2.203491347348963 | structuurschema | 0.49895065401126204 | \n",
       " | racisme | 2.428558124460832 | tegenvallers | 0.5853055751325945 | calamiteit | 0.9561950655887234 | soedanese | 1.2256536604819206 | les | 0.8187585695385503 | integratiebeleid | 0.8669374330646434 | mislukt | 0.6052562887333139 | dorpen | 0.7648423466816193 | zorgvraag | 2.203491347348963 | schapen | 0.49895065401126204 | \n",
       " | revu | 2.428558124460832 | topman | 0.5853055751325945 | ptt | 0.9561950655887234 | office | 1.2256536604819206 | rijksmiddelen | 0.8187585695385503 | anw | 0.8669374330646434 | grip | 0.6052562887333139 | bedrijvigheid | 0.7648423466816193 | tandheelkunde | 2.203491347348963 | gebiedsgerichte | 0.49895065401126204 | \n",
       " | vreemdelingencirculaire | 2.428558124460832 | ozb | 0.5853055751325945 | telefoon | 0.9561950655887234 | war | 1.2256536604819206 | sponsor | 0.8187585695385503 | samenwonen | 0.8669374330646434 | opererende | 0.6052562887333139 | koepel | 0.7648423466816193 | bijsluiter | 2.203491347348963 | ethisch | 0.49895065401126204 | \n",
       " | cbp | 2.428558124460832 | uitgeverijen | 0.5853055751325945 | prognose | 0.9561950655887234 | kernwapens | 1.2256536604819206 | creatief | 0.8187435943677542 | gerespecteerd | 0.8669227486948543 | zomaar | 0.6052562887333139 | onroerend | 0.7648423466816193 | voorschrijfgedrag | 2.203491347348963 | aardappelen | 0.49895065401126204 | \n",
       " | vreemdelingendiensten | 2.428558124460832 | rechtsbescherming | 0.5853055751325945 | zand | 0.9561950655887234 | mensenrechtenactivist | 1.2256536604819206 | vo | 0.8187435943677542 | gemeentebesturen | 0.8669227486948543 | gejaagd | 0.6052562887333139 | klimaatverandering | 0.7648423466816193 | thuiszorginstelling | 2.203491347348963 | natuurgebieden | 0.49895065401126204 | \n",
       " | vuurwapens | 2.428558124460832 | lening | 0.5853055751325945 | ameland | 0.9561950655887234 | mensenrechtenverdragen | 1.2256536604819206 | homoseksualiteit | 0.8187435943677542 | kroon | 0.8669227486948543 | xiii | 0.6052562887333139 | vrijkomen | 0.7648423466816193 | ziektekostenverzekering | 2.203491347348963 | uitbraak | 0.49893321294885873 | \n",
       " | beveiligingsmaatregelen | 2.428558124460832 | bewindvoerder | 0.5853055751325945 | milieueffecten | 0.9561950655887234 | declaration | 1.2256536604819206 | ergste | 0.8187435943677542 | veeleer | 0.8669227486948543 | dollar | 0.6052562887333139 | opruimen | 0.7648423466816193 | ciz | 2.203491347348963 | houdend | 0.49893321294885873 | \n",
       " | verhoor | 2.428558124460832 | toegepaste | 0.5852925542778851 | aanschaffen | 0.9561950655887234 | leider | 1.2256536604819206 | versnippering | 0.8187435943677542 | toetst | 0.8669227486948543 | consortium | 0.6052434338205386 | kopers | 0.7648423466816193 | genezer | 2.203491347348963 | polder | 0.49893321294885873 | \n",
       " | ontvlucht | 2.428558124460832 | element | 0.5852925542778851 | mer | 0.9561950655887234 | gevangene | 1.2256536604819206 | nogal | 0.8187435943677542 | zomerreces | 0.8669227486948543 | verbindingen | 0.6052434338205386 | velzen | 0.7648423466816193 | palliatieve | 2.203491347348963 | subsidiebedrag | 0.49893321294885873 | \n",
       " | heropenen | 2.4285448893752846 | verspreiden | 0.5852925542778851 | stimulans | 0.9561950655887234 | says | 1.2256536604819206 | stevige | 0.8187435943677542 | cnv | 0.8669227486948543 | gerelateerde | 0.6052434338205386 | wateren | 0.7648423466816193 | cak | 2.203491347348963 | nul | 0.49893321294885873 | \n",
       " | willem | 2.4285448893752846 | indirecte | 0.5852925542778851 | vlaamse | 0.9561950655887234 | bloedbad | 1.2256366223340378 | overblijven | 0.8187435943677542 | premieheffing | 0.8669227486948543 | verzameld | 0.6052434338205386 | vuurwerk | 0.7648423466816193 | specialist | 2.2034690522114957 | natuurlijk | 0.49893321294885873 | \n",
       " | arbeidsrecht | 2.4285448893752846 | efficiënt | 0.5852925542778851 | aanleggen | 0.9561950655887234 | action | 1.2256366223340378 | regeringsstandpunt | 0.8187322537952991 | halsema | 0.8669227486948543 | verzamelde | 0.6052434338205386 | verhandeld | 0.7648423466816193 | sporters | 2.2034690522114957 | besmettelijke | 0.49893321294885873 | \n",
       " | heren | 2.4285448893752846 | automatische | 0.5852925542778851 | snelheden | 0.9561950655887234 | law | 1.2256366223340378 | bezorgen | 0.8187322537952991 | kinderarbeid | 0.8669227486948543 | importeur | 0.6052434338205386 | brandstoffen | 0.7648423466816193 | buitengewone | 2.2034690522114957 | fte | 0.49893321294885873 | \n",
       " | lekken | 2.4285448893752846 | liter | 0.5852925542778851 | deadline | 0.9561950655887234 | understanding | 1.2256366223340378 | veiling | 0.8187322537952991 | lukt | 0.8669116989112152 | vervaardigd | 0.6052434338205386 | veroorzaakte | 0.7648423466816193 | contracteren | 2.2034690522114957 | japanse | 0.4989194066201563 | \n",
       " | belemmerend | 2.4285448893752846 | leermiddelen | 0.5852925542778851 | passeren | 0.9561950655887234 | herald | 1.2256366223340378 | gezette | 0.8187322537952991 | administratiekantoor | 0.8669116989112152 | voetbal | 0.6052434338205386 | complex | 0.7648423466816193 | ambulances | 2.2034690522114957 | benutting | 0.4989194066201563 | \n",
       " | bewaard | 2.4285448893752846 | stemt | 0.5852925542778851 | voorleggen | 0.9561845177713224 | an | 1.2256366223340378 | anoniem | 0.8187322537952991 | beoordelingen | 0.8669116989112152 | minima | 0.6052434338205386 | benutting | 0.7648423466816193 | dosis | 2.2034690522114957 | beleidsmatig | 0.4989194066201563 | \n",
       " | bvd | 2.4285448893752846 | ruimen | 0.5852925542778851 | keus | 0.9561845177713224 | inlichtingendienst | 1.2256366223340378 | uitgerust | 0.8187322537952991 | explosief | 0.8669116989112152 | overheidsdiensten | 0.6052434338205386 | gemodificeerde | 0.7648423466816193 | medicatie | 2.2034690522114957 | session | 0.4989194066201563 | \n",
       " | auteurswet | 2.4285448893752846 | leeftijdsdiscriminatie | 0.5852925542778851 | materialen | 0.9561845177713224 | multilaterale | 1.2256366223340378 | arnhemse | 0.8187322537952991 | privaat | 0.8669116989112152 | concurrerende | 0.6052434338205386 | bestaand | 0.7648423466816193 | medical | 2.2034690522114957 | produktie | 0.4989194066201563 | \n",
       " | implicaties | 2.4285448893752846 | opvolger | 0.5852925542778851 | opruimen | 0.9561845177713224 | koerdische | 1.2256366223340378 | beantwoordt | 0.8187322537952991 | vloeien | 0.8669116989112152 | voorkomend | 0.6052434338205386 | milieueffecten | 0.7648306616237612 | verkorten | 2.2034690522114957 | afgewacht | 0.4989194066201563 | \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topfeatures_MD2 = top_MI_to_markdown(topfeatures2_30)\n",
    "\n",
    "# bug is because of empty classes & not being able to recognize classes in normalized form\n",
    "\n",
    "display(Markdown(topfeatures_MD2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Evaluate your classifiers using Precision, Recall and F1. (Give a table in which you show these values for using the top 10, top 100 terms and all terms, for all of your 10 classes)\n",
    "          Thus do feature selection per class, and use for each class the top n best features for that class. \n",
    "          <br/>\n",
    "      Also show the microaverage(s) for all 10 classes together.\n",
    "      <br/>\n",
    "      If you like you can also present this in a figure like MRS.13.8. \n",
    "      Then compute the F1 measure for the same number of terms as in that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp, tpfp):\n",
    "    return tp/(tpfp)\n",
    "    \n",
    "def recall(guesses, classes):\n",
    "    return guesses/classes\n",
    "    \n",
    "def F1_measure(P, R):\n",
    "    return 2*P*R/(P+R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getstats_macro_fix(vocabs, test):\n",
    "    \"\"\" takes a vocabulary and testset and collects performance in Precision, Recall & F1 per class\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for vocab in vocabs:\n",
    "        print(\"starting with vocab\")\n",
    "        recall_dict = {c:{'retrieved':0, 'total relevant':len(test.loc[test[\"ministerie\"] == c, \"ministerie\"])} for c in classes} \n",
    "        precision_dict = {c:{'tp':1, 'tp+fp':1} for c in classes}\n",
    "        \n",
    "        for i, query in enumerate(test.vraag):\n",
    "            guess = ApplyMultinomialNB(classes, class_priors, cond_prob, query, Vocab=vocab)\n",
    "            if guess == test.ministerie[i]:\n",
    "                recall_dict[guess]['retrieved'] += 1\n",
    "                precision_dict[guess]['tp'] += 1\n",
    "                precision_dict[guess]['tp+fp'] += 1\n",
    "            else:\n",
    "                precision_dict[guess]['tp+fp'] += 1\n",
    "        \n",
    "        \n",
    "        P = [precision(precision_dict[c]['tp'], precision_dict[c]['tp+fp']) for c in recall_dict.keys()]\n",
    "        R = [recall(recall_dict[c]['retrieved'], recall_dict[c]['total relevant']) for c in recall_dict.keys()]\n",
    "        F1 = [F1_measure(p, r) for p,r in zip(P,R)]\n",
    "        \n",
    "        results.extend((p,r,f1,c) for p,r,f1,c in zip(P,R,F1,[c for c in recall_dict.keys()]))\n",
    "        return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Justitie', 'Financien', 'Verkeer en Waterstaat', 'Buitenlandse Zaken', 'Onderwijs, Cultuur en Wetenschappen', 'Sociale Zaken en Werkgelegenheid', 'Economische Zaken', 'Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer', 'Volksgezondheid, Welzijn en Sport', 'Landbouw, Natuurbeheer en Visserij']\n",
      "[(0.9188940092165898, 0.5476779334982138, 0.6863051956933509), (0.43393466601657726, 0.7451802179379715, 0.5484784110409693), (0.7981220657276995, 0.6809851088201604, 0.734915293677067), (0.8373493975903614, 0.8127742564602632, 0.8248788293572038), (0.7298888162197514, 0.8234859675036927, 0.7738675872594257), (0.6521739130434783, 0.7866394001363326, 0.7131233649865079), (0.4206036745406824, 0.6293018682399213, 0.5042104596876831), (0.6941923774954628, 0.6151368760064412, 0.6522779954666645), (0.9498873873873874, 0.5980844271018092, 0.7340092998841676), (0.35188047398248323, 0.8430160692212608, 0.4965131009870975)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#micro = getstats_microavg()\n",
    "# KLS: commented out because it takes a long time, my results are stored below\n",
    "# macro = getstats_macroavg()\n",
    "#macro = [(0.04666320586029878, 1.0, 0.08916565634299571), (0.10070946530541616, 1.0, 0.18299009589687157), (0.1626002191844033, 1.0, 0.2797181980551696), (0.06881236661475457, 1.0, 0.12876416621694547), (0.07809886370190922, 1.0, 0.14488256380075973), (0.11830189767549172, 1.0, 0.21157416958943676), (0.08461671569475687, 1.0, 0.15603063178047225), (0.20989790621214743, 1.0, 0.34696796338672775), (0.07163869181519295, 1.0, 0.13369933796221542), (0.058660667935629004, 1.0, 0.11082052958483166), (0.04666320586029878, 1.0, 0.08916565634299571), (0.10070946530541616, 1.0, 0.18299009589687157), (0.1626002191844033, 1.0, 0.2797181980551696), (0.06881236661475457, 1.0, 0.12876416621694547), (0.07809886370190922, 1.0, 0.14488256380075973), (0.11830189767549172, 1.0, 0.21157416958943676), (0.08461671569475687, 1.0, 0.15603063178047225), (0.20989790621214743, 1.0, 0.34696796338672775), (0.07163869181519295, 1.0, 0.13369933796221542), (0.058660667935629004, 1.0, 0.11082052958483166), (0.04666320586029878, 1.0, 0.08916565634299571), (0.10070946530541616, 1.0, 0.18299009589687157), (0.1626002191844033, 1.0, 0.2797181980551696), (0.06881236661475457, 1.0, 0.12876416621694547), (0.07809886370190922, 1.0, 0.14488256380075973), (0.11830189767549172, 1.0, 0.21157416958943676), (0.08461671569475687, 1.0, 0.15603063178047225), (0.20989790621214743, 1.0, 0.34696796338672775), (0.07163869181519295, 1.0, 0.13369933796221542), (0.058660667935629004, 1.0, 0.11082052958483166)]\n",
    "\n",
    "#vocabs = [V, topvocab10, topvocab100]\n",
    "vocabs = [V]\n",
    "\n",
    "#macro = getstats_macro_fix(vocabs, test)\n",
    "print(macro)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9188940092165898, 0.5476779334982138, 0.6863051956933509), (0.43393466601657726, 0.7451802179379715, 0.5484784110409693), (0.7981220657276995, 0.6809851088201604, 0.734915293677067), (0.8373493975903614, 0.8127742564602632, 0.8248788293572038), (0.7298888162197514, 0.8234859675036927, 0.7738675872594257), (0.6521739130434783, 0.7866394001363326, 0.7131233649865079), (0.4206036745406824, 0.6293018682399213, 0.5042104596876831), (0.6941923774954628, 0.6151368760064412, 0.6522779954666645), (0.9498873873873874, 0.5980844271018092, 0.7340092998841676), (0.35188047398248323, 0.8430160692212608, 0.4965131009870975)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'topfeatures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-34ce7326f025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mvocabs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"V = all\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmeasures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Precision\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Recall\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mshow_macro\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats_to_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmacro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshow_macro\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mshow_micro\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmicro\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-34ce7326f025>\u001b[0m in \u001b[0;36mstats_to_markdown\u001b[1;34m(stats, vocabs, measures)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mstats_to_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfirstline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclasses_table_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues_to_markdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfirstline\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topfeatures' is not defined"
     ]
    }
   ],
   "source": [
    "def stats_to_markdown(stats, vocabs, measures):\n",
    "    firstline = classes_table_markdown(topfeatures)\n",
    "    values = values_to_markdown(stats, vocabs, measures)\n",
    "    return firstline + values\n",
    "\n",
    "def values_to_markdown(stats, vocabs, measures):\n",
    "    print(\"Macro averages\")\n",
    "    returnstring = \"\"\n",
    "    stats1 = stats[:9]\n",
    "    stats2 = stats[9:19]\n",
    "    stats3 = stats[19:]\n",
    "    for i, stat in enumerate([stats1, stats2, stats3]):\n",
    "        returnstring += \" | \" + vocabs[i] + \" | \\n\"\n",
    "        for j, measure in enumerate(measures):\n",
    "            for s in stats:\n",
    "                returnstring += \" | \" + measure + \" | \" + str((s[j]))\n",
    "            returnstring += \" | \\n\"\n",
    "            \n",
    "    return returnstring\n",
    "\n",
    "def show_micro(stats, vocabs, measures):\n",
    "    print(\"Micro averages \\n\")\n",
    "    for i, vocab in enumerate(vocabs):\n",
    "        print(vocab + \":\")\n",
    "        for j, measure in enumerate(measures):\n",
    "            print(measure + \" = \" + str(stats[i][j]))\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(macro)\n",
    "vocabs = [\"V = all\"]\n",
    "measures = [\"Precision\", \"Recall\", \"F1\"]\n",
    "show_macro = stats_to_markdown(macro, vocabs, measures)\n",
    "display(Markdown(show_macro))\n",
    "show_micro(micro, vocabs, measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 \n",
    "You have done the complete implementation by yourself. Congratulations! You can also use `scikit-learn` routines for all of this work. Do that. So follow [this text classification tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)  and implement the same steps but now with your kamervragen dataset. Also use [mutual information feature selection](http://scikit-learn.org/stable/modules/feature_selection.html) to select the K-best features, and compare the results as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "\n",
    "def make_bunch(kvrdf, classes):\n",
    "    \"\"\" \n",
    "    Constructs a sklearn Bunch object from a pandas dataframe. A Bunch is an Object similar to a Python dictionary\n",
    "    that provides attribute-style access. (dataset[\"target\"] == dataset.target)\n",
    "    Input: pandas df, list of class names\n",
    "    \"\"\"\n",
    "\n",
    "    kvrdf_np = kvrdf.values\n",
    "    class_names = list(kvrdf_np[:][:, 5])\n",
    "    data = list(kvrdf_np[:][:,3])\n",
    "    classes = list(classes)\n",
    "\n",
    "    target = []\n",
    "    x = 0\n",
    "    for name in class_names:\n",
    "        target.append(classes.index(name)) \n",
    "\n",
    "    \n",
    "    dataset = datasets.base.Bunch(data=data, target=target, target_names=classes)\n",
    "    return(dataset)\n",
    "    \n",
    "kvrdf_train, kvrdf_test = train_test_split(kvrdf, test_size=0.2)\n",
    "dataset = make_bunch(kvrdf_train, classes)\n",
    "test_dataset = make_bunch(kvrdf_test, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing text files with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Build a dictionary of features and transforms documents to feature vectors\n",
    "# Absolute word count\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(dataset.data)\n",
    "X_train_counts.shape\n",
    "\n",
    "# CALCULATE TF AND IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature SELECTION\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X, y = X_train_tfidf, dataset.target\n",
    "X.shape\n",
    "selectkbest = SelectKBest(chi2, k=5000)\n",
    "X_new = selectkbest.fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING A CLASSIFIER\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_new, dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Trying classifier on test data\n",
    "X_new_counts = count_vect.transform(test_dataset.data)\n",
    "\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "X_selected_f = selectkbest.transform(X_new_tfidf)\n",
    "\n",
    "\n",
    "predicted = clf.predict(X_selected_f)\n",
    "\n",
    "print(np.mean(predicted == test_dataset.target))\n",
    "\n",
    "# for doc, category in zip(docs_new, predicted):\n",
    "#     print('%r => %s' % (doc, dataset.target_names[category]))\n",
    "#     print(\"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of implementing everything yourself, you can also use a library, such as scikit-learn, for text classification. In the scikit-learn tutorial for naive Bayes classification, there are examples that walk you through all the steps of using the library to implement a naive Bayes classifier. First the data has to be loaded into Python. In the tutorial a scikit-learn Bunch object was used, so we opted to use this data type, as it would make it easier to follow along with the tutorial.\n",
    "\n",
    "After loading in the data, the documents are tokenized the documentes are transformed into feature vectors, with a CountVectorizer() object. Counting the absolute occurence of words is a good start, but there is a problem. Documents of different lengths about the same subject have different count values. We therefore use term frequencies instead of absolute word count.\n",
    "\n",
    "Scikit-learn has built-in functionality for feature selection. Here, we've selected the K-best features with SelectKBest. We experimented with different values for K and we seemed to get the best results with a value for K around 5000.\n",
    "\n",
    "Using this transformed training data, we trained a Naive Bayes classifier with MultinomialNB and applied the classifier to our training data.\n",
    "\n",
    "This led to an overall performance of 0.5893604303646145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "\n",
    "Reflect and report briefly about your choices in this process and about the obtained results. Also reflect on the differences between the scikit learn approach and the \"own implementation approach\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training/Testing</h3>\n",
    "<p>It is important that you do not test your classifier using documents that have also been used in training.\n",
    "    So split up your collection in a training set and a test set. A 80%-20% split is reasonable.\n",
    "\n",
    "<br/>\n",
    "    If you have too little data you can use 5 or <a href=\"http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\">10-fold cross validation</a>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Form of handing in your final product</h2>\n",
    "\n",
    "* An IPython notebook with for each question, a MarkDown cell containing the question, a code cell which solves the question, an output cell with the output, followed by a MarkDown cell with explanation/reflection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
