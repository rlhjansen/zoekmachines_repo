{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Text classification with Naive Bayes  \n",
    "        \n",
    "        \n",
    "        \n",
    "<h3>Abstract</h3>\n",
    "<p>We will do text classification on a collection of Dutch parliamentary questions.\n",
    "    The website <a href=\"https://zoek.officielebekendmakingen.nl/zoeken/parlementaire_documenten\">officielebekendmakingen.nl</a>lets you search in \"kamervragen\".\n",
    "    <!--You can donwload\n",
    "    <a href='http://data.politicalmashup.nl/kamervragen/PoliDocs_Kamervragen.zip'>this zipfile with Kamervragen in XML</a>\n",
    "    to see some of the  data in XML format. \n",
    "    It also contains style sheets to show the XML well in a browser.  \n",
    "-->\n",
    "    The <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/'>MYSQL directory</a> contains an <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR14807.xml'>example   Kamervraag XML file</a> and a file `kvr.csv.gz` with 40K kamervragen in a handy csv format. Note that in your browser you see the result of applying stylesheets. So choose View Source or open it in an editor.</p>\n",
    "\n",
    "<h3>First exploration</h3>\n",
    "\n",
    "See below.\n",
    "\n",
    "<h2>Exercises</h2>\n",
    "\n",
    "<p>We will use the fields in elements of the form <tt> &lt;item attribuut=\"Afkomstig_van\"></tt> as our classes. \n",
    "    These are the ministeries to whom the question is addressed.\n",
    "    An example is \n",
    "    <pre>\n",
    "        &lt;item attribuut=\"Afkomstig_van\">Landbouw, Natuurbeheer en Visserij (LNV)&lt;/item>\n",
    "    </pre>\n",
    "    Note that these labels are <strong>not normalized</strong>, see e.g. the counts below:\n",
    "    <pre>\n",
    "Justitie (JUS)                                                   3219\n",
    "Volksgezondheid, Welzijn en Sport (VWS)                          2630\n",
    "Buitenlandse Zaken (BUZA)                                        1796\n",
    "Verkeer en Waterstaat (VW)                                       1441\n",
    "Justitie                                                         1333\n",
    "Sociale Zaken en Werkgelegenheid (SZW)                           1231\n",
    "Onderwijs, Cultuur en Wetenschappen (OCW)                        1187\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer (VROM)     984\n",
    "FinanciÃ«n (FIN)                                                   960\n",
    "Volksgezondheid, Welzijn en Sport                                 951\n",
    "Economische Zaken (EZ)                                            946\n",
    "Buitenlandse Zaken                                                753\n",
    "Binnenlandse Zaken en Koninkrijksrelaties (BZK)                   725\n",
    "Verkeer en Waterstaat                                             724\n",
    "Defensie (DEF)                                                    646\n",
    "Sociale Zaken en Werkgelegenheid                                  607\n",
    "Landbouw, Natuurbeheer en Visserij (LNV)                          586\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer            554\n",
    "Onderwijs, Cultuur en Wetenschappen                               532\n",
    "Vreemdelingenzaken en Integratie (VI)                             466\n",
    "    </pre>\n",
    "</p>\n",
    "\n",
    "\n",
    "<h2>Form of handing in your final product</h2>\n",
    "\n",
    "* An IPython notebook with for each question, a MarkDown cell containing the question, a code cell which solves the question, an output cell with the output, followed by a MarkDown cell with explanation/reflection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaar</th>\n",
       "      <th>partij</th>\n",
       "      <th>titel</th>\n",
       "      <th>vraag</th>\n",
       "      <th>antwoord</th>\n",
       "      <th>ministerie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KVR1000.xml</th>\n",
       "      <td>1994</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>De vragen betreffen de betrouwbaarheid van de...</td>\n",
       "      <td>Hebt u kennisgenomen van het televisieprogram...</td>\n",
       "      <td>Ja. Het bedoelde geluidmeetpunt is eigendom v...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10000.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen naar aanleiding van berichten (uitzend...</td>\n",
       "      <td>Kent u de berichten over de situatie in de Me...</td>\n",
       "      <td></td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10001.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>SP</td>\n",
       "      <td>Vragen naar aanleiding van de berichten \"Nede...</td>\n",
       "      <td>Kent u de berichten «Nederland steunt de Soeh...</td>\n",
       "      <td></td>\n",
       "      <td>Financien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10002.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen over de gebrekkige opvang van verpleeg...</td>\n",
       "      <td>Kent u het bericht over onderzoek van Nu91 me...</td>\n",
       "      <td>Ja. Het onderzoek van NU’91 wijst uit dat het...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10003.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen over onbetrouwbaarheid van filemeldingen.</td>\n",
       "      <td>Hebt u kennisgenomen van de berichten over de...</td>\n",
       "      <td>Ja. Nee. Door de waarnemers van het Algemeen ...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                jaar partij  \\\n",
       "KVR1000.xml     1994   PvdA   \n",
       " KVR10000.xml   1999   PvdA   \n",
       " KVR10001.xml   1999     SP   \n",
       " KVR10002.xml   1999   PvdA   \n",
       " KVR10003.xml   1999   PvdA   \n",
       "\n",
       "                                                           titel  \\\n",
       "KVR1000.xml     De vragen betreffen de betrouwbaarheid van de...   \n",
       " KVR10000.xml   Vragen naar aanleiding van berichten (uitzend...   \n",
       " KVR10001.xml   Vragen naar aanleiding van de berichten \"Nede...   \n",
       " KVR10002.xml   Vragen over de gebrekkige opvang van verpleeg...   \n",
       " KVR10003.xml   Vragen over onbetrouwbaarheid van filemeldingen.   \n",
       "\n",
       "                                                           vraag  \\\n",
       "KVR1000.xml     Hebt u kennisgenomen van het televisieprogram...   \n",
       " KVR10000.xml   Kent u de berichten over de situatie in de Me...   \n",
       " KVR10001.xml   Kent u de berichten «Nederland steunt de Soeh...   \n",
       " KVR10002.xml   Kent u het bericht over onderzoek van Nu91 me...   \n",
       " KVR10003.xml   Hebt u kennisgenomen van de berichten over de...   \n",
       "\n",
       "                                                        antwoord  \\\n",
       "KVR1000.xml     Ja. Het bedoelde geluidmeetpunt is eigendom v...   \n",
       " KVR10000.xml                                                      \n",
       " KVR10001.xml                                                      \n",
       " KVR10002.xml   Ja. Het onderzoek van NU’91 wijst uit dat het...   \n",
       " KVR10003.xml   Ja. Nee. Door de waarnemers van het Algemeen ...   \n",
       "\n",
       "                                       ministerie  \n",
       "KVR1000.xml                 Verkeer en Waterstaat  \n",
       " KVR10000.xml                            Justitie  \n",
       " KVR10001.xml                           Financien  \n",
       " KVR10002.xml   Volksgezondheid, Welzijn en Sport  \n",
       " KVR10003.xml               Verkeer en Waterstaat  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names=['jaar', 'partij','titel','vraag','antwoord','ministerie']\n",
    "\n",
    "# Change to KVR1000.csv.gz if this becomes too slow for you\n",
    "# kvrdf= pd.read_csv('http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR.csv.gz', \n",
    "kvrdf= pd.read_csv('http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR1000.csv.gz', \n",
    "                   compression='gzip', sep='\\t', \n",
    "                   index_col=0, names=names,\n",
    "                   ) \n",
    "\n",
    "for kolom in names[1:]:\n",
    "    kvrdf[kolom]= kvrdf[kolom].astype(str)\n",
    "print(kvrdf.shape)\n",
    "kvrdf.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from math import log\n",
    "\n",
    "DutchStop= stopwords.words('dutch')\n",
    "allvragen= '\\n'.join(list(kvrdf.titel))\n",
    "classes = list(set(list(kvrdf.ministerie)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words are treated as lowercase & stopwords are filtered out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequencies per word\n",
    "\n",
    "def strip_string(string):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param string: string of unfiltered word/symbols\n",
    "    :return: list of all tokens extracted from the string (lowercasing, stopwords, alpha)\n",
    "    \"\"\"\n",
    "    return [w for w in nltk.word_tokenize(string.lower()) if w.isalpha() and not w in set(DutchStop)]\n",
    "    \n",
    "def str_to_tf(string):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param string: string of unfiltered word/symbols\n",
    "    :return: dictionary of all term frequencies: occurance of term in string\n",
    "    \"\"\"\n",
    "    return Counter(strip_string(string))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str_to_tk(string):\n",
    "    \"\"\" returns token count in a string\n",
    "    \"\"\"\n",
    "    return len(strip_string(string))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "Normalize the values for \"ministerie\" and choose 10 ministeries to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Justitie', 'Volksgezondheid, Welzijn en Sport', 'Buitenlandse Zaken', 'Verkeer en Waterstaat', 'Sociale Zaken en Werkgelegenheid', 'Onderwijs, Cultuur en Wetenschappen', 'Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer', 'Landbouw, Natuurbeheer en Visserij', 'Economische Zaken', 'Financien']\n",
      "{'Justitie', 'Landbouw, Natuurbeheer en Visserij', 'Volksgezondheid, Welzijn en Sport', 'Sociale Zaken en Werkgelegenheid', 'Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer', 'Financien', 'Buitenlandse Zaken', 'Economische Zaken', 'Verkeer en Waterstaat', 'Onderwijs, Cultuur en Wetenschappen'}\n"
     ]
    }
   ],
   "source": [
    "# Only return classes that are about a single ministerie.\n",
    "def determine_classes(classes):\n",
    "    norm_classes = set()\n",
    "    \n",
    "    for c in classes:\n",
    "        add = True\n",
    "\n",
    "        if c == 'nan':\n",
    "            continue\n",
    "\n",
    "        for nc in norm_classes:\n",
    "            if nc in c:\n",
    "                add = False\n",
    "                break\n",
    "            elif c in nc:\n",
    "                norm_classes.remove(nc)\n",
    "                break\n",
    "\n",
    "        if add:\n",
    "            norm_classes.add(c)\n",
    "            \n",
    "    return norm_classes\n",
    "\n",
    "\n",
    "# Normalize class c by replacing strange e's with a normal e\n",
    "# and removing anything between parenthesis.\n",
    "def normalize_class(c):\n",
    "    nc = \"\"\n",
    "    parenthesis = False\n",
    "    \n",
    "    for char in c:\n",
    "        if char == '(':\n",
    "            parenthesis = True\n",
    "            \n",
    "        elif char == 'ë':\n",
    "            char = 'e'\n",
    "        elif char == 'Ã':\n",
    "            char = 'e'\n",
    "        elif char == '«':\n",
    "            char = ''\n",
    "            \n",
    "        if not parenthesis:\n",
    "            nc += char\n",
    "            \n",
    "        if char == ')':\n",
    "            parenthesis = False\n",
    "    \n",
    "    return nc.strip()\n",
    "\n",
    "\n",
    "def choose_10_classes(class_rows, norm_classes):\n",
    "    count = Counter()\n",
    "    for key, rows in class_rows.items():\n",
    "        key = normalize_class(key)\n",
    "        \n",
    "        if key in norm_classes:\n",
    "            count[key] += len(rows)\n",
    "            \n",
    "    return [name for name, _ in count.most_common(10)]\n",
    "\n",
    "\n",
    "def kvrdf_to_10_classes(kvrdf, norm_classes):\n",
    "    all_classes = set(kvrdf.ministerie)\n",
    "    \n",
    "    for i, c in enumerate(all_classes):\n",
    "        nc = normalize_class(c)\n",
    "        \n",
    "        if not (nc in norm_classes):\n",
    "            kvrdf = kvrdf[kvrdf.ministerie != c]\n",
    "            kvrdf.is_copy = False\n",
    "            \n",
    "        else:\n",
    "            kvrdf.loc[kvrdf[\"ministerie\"] == c] = nc\n",
    "            \n",
    "    return kvrdf\n",
    "\n",
    "            \n",
    "classes = set(kvrdf.ministerie)\n",
    "norm_classes = {normalize_class(c) for c in determine_classes(classes)}\n",
    "\n",
    "# complete rows per class\n",
    "class_rows_full = {c:kvrdf.loc[kvrdf.ministerie == c] for c in classes}\n",
    "\n",
    "print(choose_10_classes(class_rows_full, norm_classes))\n",
    "classes = choose_10_classes(class_rows_full, norm_classes)\n",
    "kvrdf = kvrdf_to_10_classes(kvrdf, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "Implement the two algorithms in Fig MRS.13.2, using your earlier code for creating term and document frequencies. It might be easier to use the representation and formula given in MRS section 13.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#document frequencies per class per term\n",
    "def TrainMultinomialNB(pd_df, classes):\n",
    "    \"\"\" more reference from p258 onwards of MRS\n",
    "    \n",
    "    :param classes: classes which are taken into account for training\n",
    "    :param pd_df: kamervragen dataframe\n",
    "    :return:\n",
    "        V: set, of terms which which are used for classification\n",
    "        class_priors: dictionary, prior probabilities for each class: P(c) prior[class]\n",
    "        cond_prob: dictionary, conditional probabilities for each term per class: P(t|c) cond[class][term]\n",
    "        dfdict: dictionary with document frequencies\n",
    "        classes: list, classes actually used, temporary until class input is synchronised with pandas dataframe\n",
    "    \"\"\"\n",
    "    class_frequency = Counter([c for c in pd_df.ministerie])\n",
    "    \n",
    "    # classes = classes # uncomment this and comment next line when classes are implemented right \n",
    "    classes = class_frequency.keys()\n",
    "    \n",
    "    # P(c)\n",
    "    class_priors = {c:class_frequency[c]/sum([class_frequency[cn] for cn in classes]) for c in classes}\n",
    "\n",
    "    # document frequencies per term\n",
    "    k = [list(set(strip_string(t))) for t in kvrdf.titel]\n",
    "    dfdict = Counter(list(itertools.chain.from_iterable(k)))\n",
    "\n",
    "    #vocabulary\n",
    "    V = set(dfdict.keys())\n",
    "    \n",
    "    # complete rows per class\n",
    "    class_rows_full = {c:kvrdf.loc[kvrdf.ministerie == c] for c in classes}\n",
    "\n",
    "    # term frequency per class\n",
    "    class_tf = {c:str_to_tf('\\n'.join(list(class_rows_full.get(c).titel))) for c in classes}\n",
    "    \n",
    "    # token count per class (for sum over Tct' in (t' in V), (p259, formula 13.6)\n",
    "    class_tk = {c:str_to_tk('\\n'.join(list(class_rows_full.get(c).titel))) for c in classes}\n",
    "\n",
    "    #P(t|c)\n",
    "    cond_prob = {t:{c:(class_tf[c][t] + 1)/(class_tk[c] + 1) for c in classes} for t in V}\n",
    "    return V, class_priors, cond_prob, dfdict, classes\n",
    "\n",
    "def filter_vocab(W, V):\n",
    "    \"\"\" \n",
    "    \n",
    "    :param W: list; stripped query\n",
    "    :param V: set; of vocab used for classification (determined by one or anoter method)\n",
    "    :return: a list of words that occur in the used vocabulary\n",
    "    \"\"\"\n",
    "    return [w for w in W if w in V]\n",
    "\n",
    "def ApplyMultinomialNB(classes, priors, conditionals, d, Vocab=None):\n",
    "    \"\"\" Applies a Naive Bayes classifier on previously derived priors & conditionals on a query d\n",
    "\n",
    "    :param classes: list, optional ministeries to classify between \n",
    "    :param Vocab: set, of terms which which are used for classification\n",
    "    :param priors: dictionary, prior probabilities for each class: P(c) prior[class]\n",
    "    :param conditionals: dictionary, conditional probabilities for each term per class: P(t|c) cond[class][term]\n",
    "    :param d: string, query\n",
    "    :return: best classification for query\n",
    "    \"\"\"\n",
    "    W = strip_string(d)\n",
    "    if Vocab:\n",
    "        W = filter_vocab(W, Vocab)\n",
    "    score = {c:log(priors[c]) for c in classes}\n",
    "    for k in score.keys():\n",
    "        score[k] += sum([log(conditionals[t][k]) for t in W])    \n",
    "    best_class = sorted(score, key = lambda key: score[key])[0]\n",
    "    return best_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "On this collection, train NB text classifiers for 10 different classes with enough and interesting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, class_priors, cond_prob, dfdict, classes = TrainMultinomialNB(kvrdf, classes)\n",
    "ApplyMultinomialNB(classes, class_priors, cond_prob, \"vragen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "Compute for each term and each of your 10 classes its utility for that class using mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_class_df(pddf, classes):\n",
    "    class_dfdict = {c:{} for c in classes}\n",
    "\n",
    "    for i, c in enumerate(classes):\n",
    "        for d in kvrdf[kvrdf.ministerie == c].titel:\n",
    "            for elem in set(strip_string(d)):\n",
    "                if class_dfdict[c].get(elem, 0):\n",
    "                    class_dfdict[c][elem] += 1\n",
    "                else:\n",
    "                    class_dfdict[c][elem] = 1\n",
    "    return class_dfdict\n",
    "\n",
    "cddf = extract_class_df(kvrdf, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI(doc_freq, class_doc_freq):\n",
    "    \"\"\" creates a mutual information dictionary for each term, class pair\n",
    "    \n",
    "    :param doc_freq: dictionary, contains documents frequencies per term, doc_freq[term]\n",
    "    :param class_doc_freq: dictionary, contains documents frequencies per term per class, cdf[class][term]\n",
    "    :return MIdict: dictionary, contains mutual information for each class/term pair, MI[class][term]\n",
    "    \"\"\"\n",
    "    N = sum(doc_freq.values())\n",
    "    MIdict = {}\n",
    "    for c in class_doc_freq.keys():\n",
    "        MIdict[c] = {}\n",
    "        for t in class_doc_freq[c].keys():\n",
    "            N11 = class_doc_freq[c][t]\n",
    "            N10 = doc_freq[t] - N11\n",
    "            N01 = sum(class_doc_freq[c].values()) - class_doc_freq[c][t]\n",
    "            N00 = N - doc_freq[t] - (sum(class_doc_freq[c].values()) - class_doc_freq[c][t])\n",
    "            N1 = N11 + N10\n",
    "            N0 = N01 + N00\n",
    "            if N11:\n",
    "                MIdict[c][t] = N11/N * log( (N*N11)/(N1*N1), 2)\n",
    "            if N01:\n",
    "                MIdict[c][t] += N01/N * log( (N*N01)/(N0*N1) , 2)\n",
    "            if N10:\n",
    "                MIdict[c][t] += N10/N * log( (N*N10)/(N1*N0) , 2)\n",
    "            if N00:\n",
    "                MIdict[c][t] += N00/N * log(  (N*N00)/(N0*N0), 2)\n",
    "    return MIdict\n",
    "\n",
    "MIdict = MI(dfdict, cddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "For each class, show the top 10 words as in Figure 13.7 in MRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "display(Markdown(\n",
    "\"\"\"\n",
    "|some| markdown|\n",
    "|-----|------|\n",
    "| test1 | test2 | \n",
    "| test3 | test4 |\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_MI(MIdict, N):\n",
    "    \"\"\" \n",
    "    \n",
    "    :param MIdict: a dictionary with mutual information for each MIdict[class][term]\n",
    "    :param N: top N MI terms returned per class\n",
    "    :return: a dictionary of the top N MI predictors of each class    \n",
    "    \"\"\"\n",
    "    resdict = {}\n",
    "    for c in MIdict.keys():\n",
    "        resdict[c] = sorted(MIdict[c].items(), key = lambda key: -MIdict[c][key[0]])[:N]\n",
    "    return resdict\n",
    "\n",
    "def top_MI_to_markdown(topMI):\n",
    "    firstline = classes_table_markdown(topMI)\n",
    "    rest_of_table = values_table_markdown(topMI)\n",
    "    return firstline + rest_of_table\n",
    "\n",
    "\n",
    "def classes_table_markdown(topmidict):\n",
    "    return \"|\" + \" | \".join(topmidict.keys()) + \"|\\n\" + \"|\" + \" | \".join(['-----' for _ in topmidict.keys()]) + \"|\"\n",
    "\n",
    "def values_table_markdown(topmidict):\n",
    "    returnstring = \"\"\n",
    "\n",
    "    for i, elem in enumerate(topmidict[list(topmidict.keys())[0]]):\n",
    "        returnstring += \" | \" + \" | \".join([pair_to_markdown(topmidict[c][i]) for c in topmidict.keys()]) + \" | \\n\"\n",
    "    return returnstring\n",
    "            \n",
    "def pair_to_markdown(pair):\n",
    "    return pair[0] + \" | \" + str(pair[1])\n",
    "\n",
    "\n",
    "def topMI_to_vocab(topmidict):\n",
    "    vocab_l_o_l = [[elem[0] for elem in topmidict[c]] for c in topmidict.keys()]\n",
    "    return set(list(itertools.chain.from_iterable(vocab_l_o_l)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfeatures = top_MI(MIdict, 1)\n",
    "for c in topfeatures.keys():\n",
    "    print(len(topfeatures[c]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topfeatures_MD = top_MI_to_markdown(topfeatures)\n",
    "# bug is because of empty classes & not being able to recognize classes in normalized form\n",
    "\n",
    "display(Markdown(topfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "Evaluate your classifiers using Precision, Recall and F1. (Give a table in which you show these values for using the top 10, top 100 terms and all terms, for all of your 10 classes)\n",
    "          Thus do feature selection per class, and use for each class the top n best features for that class. \n",
    "          <br/>\n",
    "      Also show the microaverage(s) for all 10 classes together.\n",
    "      <br/>\n",
    "      If you like you can also present this in a figure like MRS.13.8. \n",
    "      Then compute the F1 measure for the same number of terms as in that figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def precision():\n",
    "    raise NotImplemented\n",
    "    \n",
    "def recall():\n",
    "    raise NotImplemented\n",
    "    \n",
    "def F1_measure():\n",
    "    P = precision()\n",
    "    R = recall()\n",
    "    return 2*P*R/(P+R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getstats()\n",
    "    ApplyMultinomialNB(classes, priors, conditionals, d, Vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 \n",
    "You have done the complete implementation by yourself. Congratulations! You can also use `scikit-learn` routines for all of this work. Do that. So follow [this text classification tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)  and implement the same steps but now with your kamervragen dataset. Also use [mutual information feature selection](http://scikit-learn.org/stable/modules/feature_selection.html) to select the K-best features, and compare the results as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "\n",
    "Reflect and report briefly about your choices in this process and about the obtained results. Also reflect on the differences between the scikit learn approach and the \"own implementation approach\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training/Testing</h3>\n",
    "<p>It is important that you do not test your classifier using documents that have also been used in training.\n",
    "    So split up your collection in a training set and a test set. A 80%-20% split is reasonable.\n",
    "\n",
    "<br/>\n",
    "    If you have too little data you can use 5 or <a href=\"http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\">10-fold cross validation</a>.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Form of handing in your final product</h2>\n",
    "\n",
    "* An IPython notebook with for each question, a MarkDown cell containing the question, a code cell which solves the question, an output cell with the output, followed by a MarkDown cell with explanation/reflection  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
